{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aa22b6b",
   "metadata": {},
   "source": [
    "# Day 3-Part 2: Uncertainties\n",
    "\n",
    "Uncertainties are everywhere in geosciences. Everytime we take a measurement, there are uncertainties associated to this measurement, and everytime we look at data (e.g. seismic data), there are uncertainties associated to how these data were acquired, processed, displayed and interpreted.\n",
    "\n",
    "Uncertainties (call them errors if you want) propagate through any calculation where we use measurements (or observations) with errors. If these measurements are statistically independent (they are uncorrelated with the magnitude and error of all other measurements), the general formula to propagate the errors is:\n",
    "\n",
    "### <div align=\"center\">$\\sigma_z=\\sqrt{\\left(\\frac{\\partial z}{\\partial a}\\right)^2\\left(\\sigma_a\\right)^2+\\left(\\frac{\\partial z}{\\partial b}\\right)^2\\left(\\sigma_b\\right)^2+\\left(\\frac{\\partial z}{\\partial c}\\right)^2\\left(\\sigma_c\\right)^2+\\cdots}$</div>\n",
    "\n",
    "where $z$ is a multi-variable function $z=f(a,b,c,...)$ that depends on the measurements $a$, $b$, $c$, etc. $\\sigma_z$ is the uncertainty of $z$, and $\\sigma_a$, $\\sigma_b$, $\\sigma_c$, etc., are the uncertainty of the measurements.\n",
    "\n",
    "It is relatively easy, to calculate the formula above for simple cases (e.g. sum or multiplication of two variables), but it is quite a nightmare, when the formulas become more complicated, and even worse, when we need to use several formulas to arrive to the final result.\n",
    "\n",
    "Fortunately in Python, there is a library to deal with uncertainties and propagate errors as inidcated by the equation above. This library is called [uncertainties](https://pythonhosted.org/uncertainties/). So if you have not installed `uncertainties`, please do so by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a90fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if uncertainties is not installed\n",
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca167fb8",
   "metadata": {},
   "source": [
    "In this notebook, I illustrate the use of the `uncertainties` library using three examples.\n",
    "\n",
    "## Example 1: Bed thickness\n",
    "\n",
    "The first example is problem 4 in Chapter 2 of [Ragan, Structural Geology textbook](https://www.cambridge.org/core/books/structural-geology/4D631885C9FBBCDEF90C555445ED1160#):\n",
    "\n",
    "The orientation of a sandstone unit is 245/35 (right hand rule convention). A horizontal traverse with a bearing of N10E made from the bottom to the top of the unit measured 125 m.\n",
    "\n",
    "- Calculate the thickness of the unit\n",
    "- If the uncertainty in dip is 2$^\\circ$, the uncertainty of the traverse direction is 1$^\\circ$, and the uncertainty in the measured length is 0.5%, what is the uncertainty in the calculated thickness?\n",
    "\n",
    "The figure below shows on map view the variables (measurements) for this problem, and the equation we can use to determine the thickness of the sandstone:\n",
    "\n",
    "<img src=\"../figures/ss_thickness.png\" alt=\"varTypes\" width=\"600\"/><br><br>\n",
    "\n",
    "Let's solve first this problem the hard way, by actually computing all the partial derivatives and solving for the error in quadrature formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math # Import math\n",
    "\n",
    "pi = math.pi # pi\n",
    "\n",
    "# Problem 4, chapter 2 of Ragan\n",
    "l = 125 # transect length\n",
    "l_u = l * 0.005 # uncertainty in transect length\n",
    "dip = 35 * pi/180.0 # dip in radians\n",
    "dip_u = 2 * pi/180.0 # uncertainty in dip in radians\n",
    "beta = 55 * pi/180.0 # angle of traverse with strike line in radians\n",
    "beta_u = 1 * pi/180.0 # uncertainty in beta in radians\n",
    "\n",
    "# Compute thickness of bed, Eq. 2.2 of Ragan\n",
    "t = l*math.sin(beta)*math.sin(dip)\n",
    "print(\"Thickness = {:.1f} m\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d504dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute error in thickness\n",
    "\n",
    "# Partial derivatives, here we need to use calculus\n",
    "ptl = math.sin(beta)*math.sin(dip) # partial derivative of t with respect to l\n",
    "ptb = l*math.cos(beta)*math.sin(dip) # partial derivative of t with respect to beta\n",
    "ptd = l*math.sin(beta)*math.cos(dip) # partial derivative of t with respect to dip\n",
    "\n",
    "# Quadrature formula\n",
    "t_u = math.sqrt((ptl*l_u)**2 + (ptb*beta_u)**2 + (ptd*dip_u)**2)\n",
    "\n",
    "# Output result\n",
    "print(\"Thickness = {:.1f} +/- {:.1f} m\".format(t, t_u))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cde63d2",
   "metadata": {},
   "source": [
    "So the error in thickness is about 5% the computed thickness. Now let's solve this problem using the `uncertainties` library. For that, we will need to create `ufloat`s (floats with uncertainties), and use `umath` (math with uncertainty):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e2f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainties import ufloat # float with uncertainties\n",
    "from uncertainties import umath # math with uncertainties\n",
    "\n",
    "# Define parameters with uncertainties\n",
    "l = ufloat(125, 125*0.005)\n",
    "dip = ufloat(35, 2) * pi/180\n",
    "beta = ufloat(55, 1) * pi/180\n",
    "\n",
    "# Compute thickness\n",
    "t = l*umath.sin(beta)*umath.sin(dip)\n",
    "\n",
    "# Output result\n",
    "print(\"Thickness = {:.1f} m\".format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcad376c",
   "metadata": {},
   "source": [
    "We got the same result than above but in a much more efficient way. We also demonstrated that the `uncertainties` package works. Now let's try a second example with more data.\n",
    "\n",
    "## Example 2: Error bars\n",
    "\n",
    "For this example, we are going to use again the data on trace elements concentrations in tephra deposits of a volcano in Italy. Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa681d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = os.path.join(\"..\", \"data\", \"Smith_glass_post_NYT_data.xlsx\")\n",
    "my_dataset = pd.read_excel(path, sheet_name=\"Supp_traces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eec9cb6",
   "metadata": {},
   "source": [
    "Now, suppose the concentration measurements have errors that are 10% the measured value, and that we want to make a plot of La versus the ratio of Rb/Th. Most importantly we want to calculate the errors in that ratio, and display the plot with error bars. The following code will do it. Here we use the `uncertainties.unumpy` module to make arrays with uncertainties, and the `pyplot.errorbar` function to plot the data with error bars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ede4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainties import unumpy # arrays with uncertainties\n",
    "\n",
    "epochs = [\"one\",\"two\",\"three\",\"three-b\"]\n",
    "colors = [\"#afbbb5\", \"#f10e4a\", \"#27449c\", \"#f9a20e\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "for epoch, color in zip(epochs, colors):\n",
    "    # Select data in epoch\n",
    "    my_data = my_dataset[(my_dataset.Epoch == epoch)]\n",
    "    \n",
    "    # Concentrations as numpy arrays\n",
    "    la = my_data.La.to_numpy() # La concentration\n",
    "    rb = my_data.Rb.to_numpy() # Rb concentration \n",
    "    th = my_data.Th.to_numpy() # Th concentration\n",
    "    \n",
    "    # Concentrations with uncertainties = 10% measured value\n",
    "    la = unumpy.uarray(la, la*0.1) # La concentration\n",
    "    rb = unumpy.uarray(rb, rb*0.1) # Rb concentration\n",
    "    th = unumpy.uarray(th, th*0.1) # Th concentration\n",
    "    \n",
    "    # Compute Rb/Th\n",
    "    rb_th = rb / th # Rb/Th with uncertainties\n",
    "    \n",
    "    # Plot data with uncertainties\n",
    "    x = unumpy.nominal_values(la) # nominal values of La\n",
    "    y = unumpy.nominal_values(rb_th) # nominal values of Rb/Th\n",
    "    xerr = unumpy.std_devs(la) # uncertainties in La\n",
    "    yerr = unumpy.std_devs(rb_th) # uncertainties in Rb/Th\n",
    "    \n",
    "    ax.errorbar(x=x, y=y, xerr=xerr, yerr=yerr, linestyle=\"\", \n",
    "                markerfacecolor= color, markersize=6, marker=\"o\", \n",
    "                markeredgecolor=\"k\", ecolor= color, elinewidth=0.5, capsize=0, \n",
    "                label=\"Epoch \" + epoch)\n",
    "    \n",
    "ax.legend(title=\"CFC Recent Activity\")\n",
    "ax.set_ylabel(\"Rb/Th\")\n",
    "ax.set_xlabel(\"La [ppm]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f491f8",
   "metadata": {},
   "source": [
    "Isn't that cool? That saved us a lot of time. Most importantly, we could produce a meaningful plot with the uncertainties (error bars) included. Let's try a final example.\n",
    "\n",
    "## Example 3: Calculating reserve volumes\n",
    "\n",
    "Suppose we have an isochore map (a contour map of vertical thickness) of net oil in a trap, and we want to estimate the total volume of oil. The Excel file `net_oil.xlsx` contains the x (east), y (north), and z (thickness value) of the contours. Let's read this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf03b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read contours of net_oil map\n",
    "path = os.path.join(\"..\", \"data\", \"net_oil.xlsx\") \n",
    "net_oil = pd.read_excel(path)\n",
    "\n",
    "net_oil.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d1037f",
   "metadata": {},
   "source": [
    "Let's assume the uncertainties in the x and y coordinates of the contours are 5 m, and the uncertainty in thickness is 1 m. Also, the contour interval, or thickness difference between adjacent contours, is 5 m. We use that information to make an array of contour values with uncertainties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3db2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# uncertainties in x (east) and y (north) of contour points, and contour values\n",
    "unc_x = 5 # uncertainty in x is 5 m\n",
    "unc_y = 5 # uncertainty in y is 5 m\n",
    "unc_z = 1 # uncertainty in contour value\n",
    "\n",
    "# contour interval is 5 m\n",
    "c_int = 5\n",
    "\n",
    "# contour values\n",
    "c_vals = np.arange(np.amin(net_oil.z), np.amax(net_oil.z)+c_int, c_int) \n",
    "c_vals = unumpy.uarray(c_vals, np.ones(c_vals.size)*unc_z)\n",
    "print(c_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6549e409",
   "metadata": {},
   "source": [
    "Let's plot the contours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ba0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot contours\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "for c_val in c_vals: # for each contour\n",
    "    my_data = net_oil[(net_oil.z == c_val.nominal_value)] # get data\n",
    "    plt.plot(my_data.x, my_data.y, label=str(c_val.nominal_value)) # plot contour\n",
    "\n",
    "# set title, legend, and axes\n",
    "ax.set_title(\"Net oil map\")\n",
    "ax.legend(title=\"Isochores in m\")\n",
    "ax.set_xlabel(\"East [m]\")\n",
    "ax.set_ylabel(\"North[m]\")\n",
    "ax.axis(\"scaled\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef5db00",
   "metadata": {},
   "source": [
    "Let's start by calculating the areas inside each contour. As we saw in lab 2, the area of a polygon made up of line segments between N vertices ($x_i, y_i$), $i=0$ to $N-1$, is:\n",
    "\n",
    "### <div align=\"center\">$A=\\frac{1}{2} \\sum_{i=0}^{N-1}\\left(x_i y_{i+1}-x_{i+1} y_i\\right)$</div>\n",
    "\n",
    "where the last vertex ($x_N, y_N$) is assumed to be the same as the first; the polygon is closed. The equation above gives a positive area if the polygon vertices are ordered counter clockwise, and vice versa. Obviously we want positive areas, so we take the absolute value of this calculation.\n",
    "\n",
    "The function below computes the area of a polygon from the x and y coordinates of its vertices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1e3870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute area\n",
    "def polyg_area(x,y):\n",
    "    \"\"\"\n",
    "    computes the area of a polygon from the x and y\n",
    "    coordinates of its vertices\n",
    "    \"\"\"\n",
    "    npoints = x.shape[0] # number of points in polygon\n",
    "    area = 0.0 # initialize area\n",
    "    \n",
    "    for i in range(npoints):\n",
    "        # 1st point\n",
    "        x1 = x[i]\n",
    "        y1 = y[i]\n",
    "        # 2nd point\n",
    "        next_i = i + 1\n",
    "        if i == npoints-1:\n",
    "            next_i = 0\n",
    "        x2 = x[next_i]\n",
    "        y2 = y[next_i]\n",
    "        # add to area\n",
    "        area += (x1*y2 - x2*y1)\n",
    "    \n",
    "    return np.absolute(area/2) # return area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e68817",
   "metadata": {},
   "source": [
    "Now, let's compute the areas of the contours and their uncertainties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c1ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize areas to zero\n",
    "areas = unumpy.uarray(np.zeros(c_vals.size), np.zeros(c_vals.size))\n",
    "\n",
    "# compute areas\n",
    "for i in range(c_vals.size): # for each contour\n",
    "    # select contour\n",
    "    my_data = net_oil[(net_oil.z == c_vals[i].nominal_value)]\n",
    "    # extract x and y coordinates of contour as numpy arrays\n",
    "    x = my_data.x.to_numpy() # this is a numpy array\n",
    "    y = my_data.y.to_numpy() # this is a numpy array\n",
    "    # add uncertainties to the x and y coordinates -> unumpy arrays\n",
    "    x = unumpy.uarray(x, np.ones(x.size)*unc_x)\n",
    "    y = unumpy.uarray(y, np.ones(y.size)*unc_y)\n",
    "    # compute area using our function\n",
    "    areas[i] = polyg_area(x,y)\n",
    "    # print area\n",
    "    print(\"Contour = {:.0f} m, area in square meters = {:0,.0f} \".format(c_vals[i].nominal_value, areas[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389846c3",
   "metadata": {},
   "source": [
    "Now we are in the position to calculate the volume of oil in the trap. We can matematically express the volume as:\n",
    "\n",
    "### <div align=\"center\">$V=\\int_a^b A(z) d z$</div>\n",
    "\n",
    "To visualize why this is the case, just imagine slicing the volume into many horizontal slices, these are esentially contours. We can then estimate the volume between each pair of adjacent contours (a trapezoidal prism), and finally sum up all the volumes to get the total volume.\n",
    "\n",
    "So, we just need to do an integration. We can do this using the `scipy.integrate` module. In the code below, we are using for the integration a trapezoidal rule `trapz`, but if you want, you can try another one (e.g. composite Simpson, `simps`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d8eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "\n",
    "vol_oil = integrate.trapz(areas, c_vals)\n",
    "print(\"The volume of oil is = {:0,.0f} cubic meters or {:0,.0f} barrels\".format(vol_oil, vol_oil*6.2898))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da9a960",
   "metadata": {},
   "source": [
    "So, for the measured oil trap and its uncertainties, the volume of oil is about 99 MMbbl $\\pm$ 10 MMbbl. Here we assume a simplistic model for uncertainties, but you could of course define uncertainties locally (e.g. at every point of the isochores), and then propagate them as we did here. The possibilities are endless ðŸ™‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
